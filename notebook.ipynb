{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, Callable\n",
    "import torchvision.datasets as Datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# project modules\n",
    "import helpers as hf\n",
    "import pandas as pd\n",
    "\n",
    "from RES_VAE_Dynamic import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "run = 24\n",
    "\n",
    "(\n",
    "    label_idxs,\n",
    "    t_idx,\n",
    "    norm_type,\n",
    "    kl_scale,\n",
    "    learning_rate,\n",
    "    nepochs,\n",
    "    image_size,\n",
    "    ch_multi,\n",
    "    num_res_blocks,\n",
    "    gpu_index,\n",
    "    latent_channels,\n",
    "    deep_model,\n",
    "    save_interval,\n",
    "    block_widths,\n",
    "    save_dir,\n",
    ") = hf.read_config(path=f\"Runs/Run_{run}/config.yml\")\n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\")  # device_index if use_cuda else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "# This code assumes there is no pre-defined test/train split and will create one for you\n",
    "print(\"-Target Image Size %d\" % image_size)\n",
    "celeb_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.CenterCrop(150),\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5, 0.5),\n",
    "    ]\n",
    ")\n",
    "batch_size = 8\n",
    "data_dir = \"../../../../../groups/kempter/chen/data\"\n",
    "# download dataset\n",
    "\n",
    "test_dataset = Datasets.CelebA(\n",
    "    data_dir, transform=celeb_transform, download=False, split=\"valid\"\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, num_workers=16, shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "def get_plotable_imgs(reconstructions):\n",
    "    imgs = np.array(reconstructions.detach().cpu().permute(2, 3, 1, 0)).copy()\n",
    "\n",
    "    for i in range(imgs.shape[3]):\n",
    "        img = imgs[:, :, :, i]\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        imgs[:, :, :, i] = img_norm\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a test image batch from the test_loader to visualise the reconstruction quality etc\n",
    "dataiter = iter(test_loader)\n",
    "\n",
    "test_images, labels = next(dataiter)\n",
    "test_labels = labels[:, label_idxs].to(device)\n",
    "test_treatment = labels[:, t_idx].to(device)\n",
    "\n",
    "# Create AE network.\n",
    "vae_net = VAE(\n",
    "    channel_in=test_images.shape[1],\n",
    "    label_dim=test_labels.shape[1],\n",
    "    image_size=image_size,\n",
    "    ch=ch_multi,\n",
    "    blocks=block_widths,\n",
    "    latent_channels=latent_channels,\n",
    "    num_res_blocks=num_res_blocks,\n",
    "    norm_type=norm_type,\n",
    "    deep_model=deep_model,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    \"Runs/Run_24/epoch9_step_47999/model_64.pt\",\n",
    "    map_location=\"cpu\",\n",
    ")\n",
    "print(\"-Checkpoint loaded!\")\n",
    "vae_net.load_state_dict(checkpoint[\"model_state_dict\"]);\n",
    "vae_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogs = get_plotable_imgs(test_images)\n",
    "\n",
    "for scale in [5,2,1.5,1,0,-0.5,-1,-3]:\n",
    "    imgs, mu, log_var, _ = vae_net(\n",
    "        test_images,\n",
    "        test_labels,\n",
    "        test_treatment + (((test_treatment + 1) % 2) - test_treatment) * scale,\n",
    "    )\n",
    "    imgs_plot = get_plotable_imgs(imgs)\n",
    "\n",
    "    ogs = np.concatenate((ogs, imgs_plot), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(ogs[:,:,:,7])\n",
    "ax.axis(\"off\")\n",
    "fig.set_figwidth(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.zeros_like(test_labels)\n",
    "test = torch.ones((8))*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mu, prior_logvar = vae_net.prior(labels)\n",
    "encoding = vae_net.encoder.sample(prior_mu, prior_logvar*1)\n",
    "imgs = vae_net.decoder(encoding, test)\n",
    "\n",
    "prior_imgs = get_plotable_imgs(imgs)\n",
    "\n",
    "plt.imshow(prior_imgs[:, :, :, 3])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.zeros((image_size * 5, image_size * 5, 3))\n",
    "test = torch.ones((1)) * 1\n",
    "\n",
    "\n",
    "for i, change1 in enumerate(np.linspace(0,2,5)):\n",
    "    for j, change2 in enumerate(np.linspace(0, 1, 5)):\n",
    "\n",
    "        labels = torch.tensor([[0, change2, 1, 1, 0, 0, 0, 0, 0, change1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "        prior_mu, prior_logvar = vae_net.prior(labels)\n",
    "        encoding = vae_net.encoder.sample(prior_mu, prior_logvar*2 )\n",
    "        img = vae_net.decoder(encoding, test-1)\n",
    "\n",
    "        prior_img = get_plotable_imgs(img)[:,:,:,0]\n",
    "\n",
    "        grid[\n",
    "            image_size * i : image_size * (i + 1),\n",
    "            image_size * j : image_size * (j + 1),\n",
    "            :,\n",
    "        ] = prior_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(grid)\n",
    "ax.axis(\"off\")\n",
    "fig.set_figheight(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.zeros((image_size * 32, image_size * 11, 3))\n",
    "\n",
    "encoding, mu, logvar = vae_net.encoder(test_images, test_labels, test_treatment)\n",
    "\n",
    "for i in range(32):\n",
    "    print(i)\n",
    "    for j, scale in enumerate(np.linspace(-30,30,11)):\n",
    "        mu_new = mu.clone()\n",
    "        mu_new[:, i] -= scale #* torch.exp(logvar[:, i])\n",
    "        img = vae_net.decoder(mu_new, test_treatment)\n",
    "\n",
    "        prior_img = get_plotable_imgs(img)[:, :, :, 1]\n",
    "\n",
    "        grid[\n",
    "            image_size * i : image_size * (i + 1),\n",
    "            image_size * j : image_size * (j + 1),\n",
    "            :,\n",
    "        ] = prior_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(grid)\n",
    "ax.axis(\"off\")\n",
    "fig.set_figheight(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 400\n",
    "df = pd.DataFrame()\n",
    "index = 0\n",
    "for i in np.arange(0,latent_channels, dtype=int):\n",
    "    for n in range(ns):\n",
    "        df.loc[index, \"g\"] = str(i)\n",
    "        df.loc[index, \"x\"] = np.random.normal(\n",
    "            np.array(mu[0, i].detach()),\n",
    "            np.array(torch.sqrt(logvar.exp())[1, i].detach()),\n",
    "        )\n",
    "        index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "pal = sns.cubehelix_palette(5, rot=-0.25, light=0.7)\n",
    "g = sns.FacetGrid(df, row=\"g\", hue=\"g\", aspect=10, height=0.2, palette=pal)\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"x\", bw_adjust=0.5, clip_on=False, fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"x\", clip_on=False, color=\"w\", lw=1, bw_adjust=0.5)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=1.5, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(\n",
    "        0,\n",
    "        0.2,\n",
    "        label,\n",
    "        #fontweight=\"bold\",\n",
    "        color=color,\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "\n",
    "\n",
    "#g.map(label, \"x\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-0.45)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data\n",
    "rs = np.random.RandomState(1979)\n",
    "x = rs.randn(500)\n",
    "g = np.tile(list(\"ABCDEFGHIJ\"), 50)\n",
    "df = pd.DataFrame(dict(x=x, g=g))\n",
    "m = df.g.map(ord)\n",
    "df[\"x\"] += m\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "pal = sns.cubehelix_palette(10, rot=-0.25, light=0.7)\n",
    "g = sns.FacetGrid(df, row=\"g\", hue=\"g\", aspect=15, height=0.5, palette=pal)\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"x\", bw_adjust=0.5, clip_on=False, fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"x\", clip_on=False, color=\"w\", lw=2, bw_adjust=0.5)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(\n",
    "        0,\n",
    "        0.2,\n",
    "        label,\n",
    "        fontweight=\"bold\",\n",
    "        color=color,\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "\n",
    "\n",
    "g.map(label, \"x\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-0.25)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
